#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
–ö—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ—ñ—è - –ö–æ–º–ø'—é—Ç–µ—Ä–Ω–∏–π –ø—Ä–∞–∫—Ç–∏–∫—É–º ‚Ññ1
–ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞ –µ–Ω—Ç—Ä–æ–ø—ñ—ó –Ω–∞ —Å–∏–º–≤–æ–ª –¥–∂–µ—Ä–µ–ª–∞ –≤—ñ–¥–∫—Ä–∏—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç—É
"""

import math
import sys
import csv
from collections import Counter, defaultdict
import argparse
import re

class TextEntropyAnalyzer:
    def __init__(self, text):
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ –∑ –ø–æ–ø–µ—Ä–µ–¥–Ω—å–æ –æ–±—Ä–æ–±–ª–µ–Ω–∏–º —Ç–µ–∫—Å—Ç–æ–º
        self.original_text = text
        self.processed_text = self.preprocess_text(text)
        self.processed_text_no_spaces = self.processed_text.replace(' ', '')
        
    def preprocess_text(self, text):
        """
        –ü–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞ —Ç–µ–∫—Å—Ç—É –∑–≥—ñ–¥–Ω–æ –∑ –≤–∏–º–æ–≥–∞–º–∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ—ó —Ä–æ–±–æ—Ç–∏:
        - –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–∞ –Ω–∏–∂–Ω—ñ–π —Ä–µ–≥—ñ—Å—Ç—Ä
        - –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ª–∏—à–µ —Ä–æ—Å—ñ–π—Å—å–∫–∏—Ö –ª—ñ—Ç–µ—Ä —Ç–∞ –ø—Ä–æ–±—ñ–ª—ñ–≤
        - –ó–∞–º—ñ–Ω–∞ –∫—ñ–ª—å–∫–æ—Ö –ø—Ä–æ–±—ñ–ª—ñ–≤ –Ω–∞ –æ–¥–∏–Ω
        - –ó–∞–º—ñ–Ω–∞ —ë –Ω–∞ –µ, —ä –Ω–∞ —å
        """
        text = text.lower()
        
        text = text.replace('—ë', '–µ')
        text = text.replace('—ä', '—å')
        
        allowed_chars = set('–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—å—ã—ç—é—è ')
        filtered_text = ''.join(char if char in allowed_chars else ' ' for char in text)
        
        # –ó–∞–º—ñ–Ω–∞ –∫—ñ–ª—å–∫–æ—Ö –ø—Ä–æ–±—ñ–ª—ñ–≤ –Ω–∞ –æ–¥–∏–Ω
        filtered_text = re.sub(r' +', ' ', filtered_text)

        return filtered_text.strip()
    
    def calculate_letter_frequencies(self, include_spaces=True):
        """–û–±—á–∏—Å–ª–µ–Ω–Ω—è —á–∞—Å—Ç–æ—Ç–∏ –∫–æ–∂–Ω–æ—ó –ª—ñ—Ç–µ—Ä–∏ –≤ —Ç–µ–∫—Å—Ç—ñ"""
        text = self.processed_text if include_spaces else self.processed_text_no_spaces
        
        if not text:
            return {}
        
        letter_counts = Counter(text)
        total_letters = len(text)
        
        frequencies = {
            letter: count / total_letters 
            for letter, count in letter_counts.items()
        }
        
        return frequencies
    
    def calculate_bigram_frequencies(self, include_spaces=True, overlapping=True):
        """
        –û–±—á–∏—Å–ª–µ–Ω–Ω—è —á–∞—Å—Ç–æ—Ç–∏ –±—ñ–≥—Ä–∞–º
        overlapping=True: –∫–æ–≤–∑–Ω–µ –≤—ñ–∫–Ω–æ –∑ –∫—Ä–æ–∫–æ–º 1
        overlapping=False: –Ω–µ–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ –±—ñ–≥—Ä–∞–º–∏ –∑ –∫—Ä–æ–∫–æ–º 2
        """
        text = self.processed_text if include_spaces else self.processed_text_no_spaces
        
        if len(text) < 2:
            return {}
        
        bigram_counts = defaultdict(int)
        step = 1 if overlapping else 2
        
        for i in range(0, len(text) - 1, step):
            bigram = text[i:i+2]
            if len(bigram) == 2:
                bigram_counts[bigram] += 1
        
        total_bigrams = sum(bigram_counts.values())
        
        frequencies = {
            bigram: count / total_bigrams 
            for bigram, count in bigram_counts.items()
        }
        
        return frequencies
    
    def calculate_H1(self, include_spaces=True):
        """–û–±—á–∏—Å–ª–µ–Ω–Ω—è –µ–Ω—Ç—Ä–æ–ø—ñ—ó H‚ÇÅ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —á–∞—Å—Ç–æ—Ç –æ–∫—Ä–µ–º–∏—Ö –ª—ñ—Ç–µ—Ä"""
        frequencies = self.calculate_letter_frequencies(include_spaces)
        
        if not frequencies:
            return 0
        
        entropy = 0
        for freq in frequencies.values():
            if freq > 0:
                entropy -= freq * math.log2(freq)
        
        return entropy
    
    def calculate_H2(self, include_spaces=True, overlapping=True):
        """–û–±—á–∏—Å–ª–µ–Ω–Ω—è –µ–Ω—Ç—Ä–æ–ø—ñ—ó H‚ÇÇ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —á–∞—Å—Ç–æ—Ç –±—ñ–≥—Ä–∞–º"""
        bigram_frequencies = self.calculate_bigram_frequencies(include_spaces, overlapping)
        
        if not bigram_frequencies:
            return 0
        
        entropy = 0
        for freq in bigram_frequencies.values():
            if freq > 0:
                entropy -= freq * math.log2(freq)
        
        # H‚ÇÇ - —Ü–µ –µ–Ω—Ç—Ä–æ–ø—ñ—è –Ω–∞ —Å–∏–º–≤–æ–ª, —Ç–æ–º—É –¥—ñ–ª–∏–º–æ –Ω–∞ 2
        return entropy / 2
    
    def export_bigram_matrix_csv(self, filename, include_spaces=True, overlapping=True):
        """–ï–∫—Å–ø–æ—Ä—Ç –º–∞—Ç—Ä–∏—Ü—ñ –±—ñ–≥—Ä–∞–º —É CSV —Ñ–∞–π–ª –∑ –ø–æ–≤–Ω–æ—é —Ç–æ—á–Ω—ñ—Å—Ç—é"""
        bigram_frequencies = self.calculate_bigram_frequencies(include_spaces, overlapping)
        
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—Å—ñ—Ö —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤
        if include_spaces:
            chars = sorted(set('–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—å—ã—ç—é—è '))
        else:
            chars = sorted(set('–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—å—ã—ç—é—è'))
        
        try:
            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.writer(csvfile)
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫: –ø–µ—Ä—à–∏–π —Å—Ç–æ–≤–ø–µ—Ü—å –ø–æ—Ä–æ–∂–Ω—ñ–π, –¥–∞–ª—ñ –≤—Å—ñ —Å–∏–º–≤–æ–ª–∏
                header = [''] + chars
                writer.writerow(header)
                
                # –ö–æ–∂–µ–Ω —Ä—è–¥–æ–∫: –ø–µ—Ä—à–∏–π —Å–∏–º–≤–æ–ª –±—ñ–≥—Ä–∞–º–∏, –¥–∞–ª—ñ —á–∞—Å—Ç–æ—Ç–∏
                for char1 in chars:
                    row = [char1]
                    for char2 in chars:
                        bigram = char1 + char2
                        freq = bigram_frequencies.get(bigram, 0)
                        row.append(freq)
                    writer.writerow(row)
            
            print(f"\n–ú–∞—Ç—Ä–∏—Ü—è –±—ñ–≥—Ä–∞–º —É—Å–ø—ñ—à–Ω–æ –µ–∫—Å–ø–æ—Ä—Ç–æ–≤–∞–Ω–∞ –≤ '{filename}'")
            print(f"–†–æ–∑–º—ñ—Ä –º–∞—Ç—Ä–∏—Ü—ñ: {len(chars)}x{len(chars)}")
            print(f"–í—Å—å–æ–≥–æ –±—ñ–≥—Ä–∞–º: {len(bigram_frequencies)}")
            print(f"–¢–∏–ø –±—ñ–≥—Ä–∞–º: {'–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ' if overlapping else '–Ω–µ–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ'}")
            print(f"–í–∫–ª—é—á–∞—î –ø—Ä–æ–±—ñ–ª–∏: {'—Ç–∞–∫' if include_spaces else '–Ω—ñ'}")
            
        except IOError as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å—ñ —Ñ–∞–π–ª—É: {e}")
            sys.exit(1)
    
    def print_letter_frequencies(self, include_spaces=True):
        """–í–∏–≤–µ–¥–µ–Ω–Ω—è —á–∞—Å—Ç–æ—Ç –ª—ñ—Ç–µ—Ä, –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω–∏—Ö –∑–∞ —Å–ø–∞–¥–∞–Ω–Ω—è–º"""
        frequencies = self.calculate_letter_frequencies(include_spaces)
        
        print("\n=== –ß–∞—Å—Ç–æ—Ç–∏ –±—É–∫–≤ ===")
        print(f"{'–ë—É–∫–≤–∞':<10}{'–ß–∞—Å—Ç–æ—Ç–∞':<15}{'–í—ñ–¥—Å–æ—Ç–æ–∫':<10}")
        print("-" * 35)
        
        # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ —á–∞—Å—Ç–æ—Ç–æ—é (–∑–∞ —Å–ø–∞–¥–∞–Ω–Ω—è–º)
        sorted_freq = sorted(frequencies.items(), key=lambda x: x[1], reverse=True)
        
        for letter, freq in sorted_freq:
            display_letter = '(–ø—Ä–æ–±—ñ–ª)' if letter == ' ' else letter
            print(f"{display_letter:<10}{freq:<15.6f}{freq*100:<10.2f}%")
    
    def print_bigram_matrix(self, include_spaces=True, overlapping=True):
        """–í–∏–≤–µ–¥–µ–Ω–Ω—è —á–∞—Å—Ç–æ—Ç –±—ñ–≥—Ä–∞–º —É –≤–∏–≥–ª—è–¥—ñ –º–∞—Ç—Ä–∏—Ü—ñ"""
        bigram_frequencies = self.calculate_bigram_frequencies(include_spaces, overlapping)
        
        # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –≤—Å—ñ—Ö —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Å–∏–º–≤–æ–ª—ñ–≤
        if include_spaces:
            chars = sorted(set('–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—å—ã—ç—é—è '))
        else:
            chars = sorted(set('–∞–±–≤–≥–¥–µ–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—å—ã—ç—é—è'))
        
        print("\n=== –ú–∞—Ç—Ä–∏—Ü—è —á–∞—Å—Ç–æ—Ç –±—ñ–≥—Ä–∞–º ===")
        print(f"–¢–∏–ø: {'–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ' if overlapping else '–Ω–µ–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ'}")
        print("(–ó–Ω–∞—á–µ–Ω–Ω—è –ø–æ–º–Ω–æ–∂–µ–Ω—ñ –Ω–∞ 1000 –¥–ª—è –∑—Ä—É—á–Ω–æ—Å—Ç—ñ —á–∏—Ç–∞–Ω–Ω—è)")
        
        # –í–∏–≤–µ–¥–µ–Ω–Ω—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
        print("   ", end="")
        for char in chars:
            display_char = '_' if char == ' ' else char
            print(f"{display_char:^3}", end="")
        print()
        
        # –í–∏–≤–µ–¥–µ–Ω–Ω—è –º–∞—Ç—Ä–∏—Ü—ñ
        for char1 in chars:
            display_char1 = '_' if char1 == ' ' else char1
            print(f"{display_char1:^3}", end="")
            for char2 in chars:
                bigram = char1 + char2
                freq = bigram_frequencies.get(bigram, 0) * 1000
                if freq > 0:
                    print(f"{freq:3.0f}", end="")
                else:
                    print("  .", end="")
            print()
    
    def print_top_bigrams(self, include_spaces=True, overlapping=True, top_n=20):
        """–í–∏–≤–µ–¥–µ–Ω–Ω—è —Ç–æ–ø N –Ω–∞–π—á–∞—Å—Ç—ñ—à–∏—Ö –±—ñ–≥—Ä–∞–º"""
        bigram_frequencies = self.calculate_bigram_frequencies(include_spaces, overlapping)
        
        print(f"\n=== –¢–æ–ø-{top_n} –Ω–∞–π—á–∞—Å—Ç—ñ—à–∏—Ö –±—ñ–≥—Ä–∞–º ===")
        print(f"–¢–∏–ø: {'–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ' if overlapping else '–Ω–µ–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ'}")
        print(f"{'–ë—ñ–≥—Ä–∞–º–∞':<10}{'–ß–∞—Å—Ç–æ—Ç–∞':<15}{'–í—ñ–¥—Å–æ—Ç–æ–∫':<10}")
        print("-" * 35)
        
        sorted_bigrams = sorted(bigram_frequencies.items(), 
                               key=lambda x: x[1], reverse=True)[:top_n]
        
        for bigram, freq in sorted_bigrams:
            display_bigram = bigram.replace(' ', '_')
            print(f"{display_bigram:<10}{freq:<15.6f}{freq*100:<10.2f}%")
    
    def calculate_redundancy(self, H_value, alphabet_size):
        """–û–±—á–∏—Å–ª–µ–Ω–Ω—è –Ω–∞–¥–ª–∏—à–∫–æ–≤–æ—Å—Ç—ñ R = 1 - H‚àû/H‚ÇÄ"""
        H0 = math.log2(alphabet_size)
        R = 1 - (H_value / H0)
        return R


class BigramPredictor:
    """–ö–ª–∞—Å –¥–ª—è —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª—É –Ω–∞ –æ—Å–Ω–æ–≤—ñ –º–∞—Ç—Ä–∏—Ü—ñ –±—ñ–≥—Ä–∞–º"""
    
    def __init__(self, csv_filename):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–∞—Ç—Ä–∏—Ü—ñ –±—ñ–≥—Ä–∞–º –∑ CSV —Ñ–∞–π–ª—É"""
        self.bigram_frequencies = {}
        self.alphabet = []
        self.load_from_csv(csv_filename)
    
    def load_from_csv(self, filename):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–∞—Ç—Ä–∏—Ü—ñ –±—ñ–≥—Ä–∞–º –∑ CSV"""
        try:
            with open(filename, 'r', encoding='utf-8') as csvfile:
                reader = csv.reader(csvfile)
                
                # –ß–∏—Ç–∞–Ω–Ω—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ (–∞–ª—Ñ–∞–≤—ñ—Ç)
                header = next(reader)
                self.alphabet = header[1:]  # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –ø–µ—Ä—à–∏–π –ø–æ—Ä–æ–∂–Ω—ñ–π –µ–ª–µ–º–µ–Ω—Ç
                
                # –ß–∏—Ç–∞–Ω–Ω—è —Ä—è–¥–∫—ñ–≤ –º–∞—Ç—Ä–∏—Ü—ñ
                for row in reader:
                    if not row:
                        continue
                    
                    char1 = row[0]
                    for i, freq_str in enumerate(row[1:]):
                        if i >= len(self.alphabet):
                            break
                        char2 = self.alphabet[i]
                        try:
                            freq = float(freq_str)
                            if freq > 0:
                                self.bigram_frequencies[(char1, char2)] = freq
                        except ValueError:
                            continue
            
            print(f"–ú–∞—Ç—Ä–∏—Ü—è –±—ñ–≥—Ä–∞–º —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∞ –∑ '{filename}'")
            print(f"–†–æ–∑–º—ñ—Ä –∞–ª—Ñ–∞–≤—ñ—Ç—É: {len(self.alphabet)}")
            print(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –±—ñ–≥—Ä–∞–º: {len(self.bigram_frequencies)}")
            
        except FileNotFoundError:
            print(f"–ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª '{filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
            sys.exit(1)
        except Exception as e:
            print(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ —á–∏—Ç–∞–Ω–Ω—ñ CSV —Ñ–∞–π–ª—É: {e}")
            sys.exit(1)
    
    def predict_next(self, char):
        """–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª—É –ø—ñ—Å–ª—è –∑–∞–¥–∞–Ω–æ–≥–æ"""
        char = char.lower()
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞, —á–∏ —Å–∏–º–≤–æ–ª —î –≤ –∞–ª—Ñ–∞–≤—ñ—Ç—ñ
        if char not in self.alphabet:
            return []
        
        # –ó–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è –≤—Å—ñ—Ö –±—ñ–≥—Ä–∞–º, —â–æ –ø–æ—á–∏–Ω–∞—é—Ç—å—Å—è –∑ —Ü—å–æ–≥–æ —Å–∏–º–≤–æ–ª—É
        predictions = []
        for (c1, c2), freq in self.bigram_frequencies.items():
            if c1 == char:
                predictions.append((c2, freq))
        
        # –°–æ—Ä—Ç—É–≤–∞–Ω–Ω—è –∑–∞ —á–∞—Å—Ç–æ—Ç–æ—é (–∑–∞ —Å–ø–∞–¥–∞–Ω–Ω—è–º)
        predictions.sort(key=lambda x: x[1], reverse=True)
        
        return predictions
    
    def run_interactive(self):
        """–ó–∞–ø—É—Å–∫ —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º—É –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è"""
        print("\n" + "=" * 60)
        print("–Ü–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ò–ô –†–ï–ñ–ò–ú –ü–ï–†–ï–î–ë–ê–ß–ï–ù–ù–Ø –ù–ê–°–¢–£–ü–ù–û–ì–û –°–ò–ú–í–û–õ–£")
        print("=" * 60)
        print("\n–í–≤–µ–¥—ñ—Ç—å —Å–∏–º–≤–æ–ª, —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏ –Ω–∞–π–±—ñ–ª—å—à –π–º–æ–≤—ñ—Ä–Ω—ñ –Ω–∞—Å—Ç—É–ø–Ω—ñ —Å–∏–º–≤–æ–ª–∏")
        print("–î–ª—è –ø—Ä–æ–±—ñ–ª—É –≤–≤–µ–¥—ñ—Ç—å '_' (–ø—ñ–¥–∫—Ä–µ—Å–ª–µ–Ω–Ω—è)")
        print("–î–ª—è –≤–∏—Ö–æ–¥—É –≤–≤–µ–¥—ñ—Ç—å 'exit' –∞–±–æ 'quit'")
        print("–î–ª—è –≤–∏–≤–µ–¥–µ–Ω–Ω—è –∞–ª—Ñ–∞–≤—ñ—Ç—É –≤–≤–µ–¥—ñ—Ç—å 'alphabet'")
        print("-" * 60)
        
        while True:
            try:
                user_input = input("\n–í–≤–µ–¥—ñ—Ç—å —Å–∏–º–≤–æ–ª: ")
                
                # –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ strip() —â–æ–± –∑–±–µ—Ä–µ–≥—Ç–∏ –ø—Ä–æ–±—ñ–ª–∏
                if not user_input:
                    continue
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–º–∞–Ω–¥ (—Ç—É—Ç –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ strip –¥–ª—è –∫–æ–º–∞–Ω–¥)
                if user_input.strip().lower() in ['exit', 'quit', '–≤–∏—Ö—ñ–¥']:
                    print("–î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è!")
                    break
                
                if user_input.strip().lower() == 'alphabet':
                    print("\n–ê–ª—Ñ–∞–≤—ñ—Ç –º–∞—Ç—Ä–∏—Ü—ñ:")
                    display_alphabet = [c if c != ' ' else '(–ø—Ä–æ–±—ñ–ª)' for c in self.alphabet]
                    print(', '.join(display_alphabet))
                    continue
                
                # –ë–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ –ø–µ—Ä—à–∏–π —Å–∏–º–≤–æ–ª
                char = user_input[0]
                
                # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –ø—ñ–¥–∫—Ä–µ—Å–ª–µ–Ω–Ω—è –≤ –ø—Ä–æ–±—ñ–ª
                if char == '_':
                    char = ' '
                
                predictions = self.predict_next(char)
                
                if not predictions:
                    display_char = char if char != ' ' else '(–ø—Ä–æ–±—ñ–ª)'
                    print(f"\n–°–∏–º–≤–æ–ª '{display_char}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –∞–ª—Ñ–∞–≤—ñ—Ç—ñ –∞–±–æ –Ω–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—Ä–æ –±—ñ–≥—Ä–∞–º–∏")
                    continue
                
                # –í–∏–≤–µ–¥–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
                display_char = char if char != ' ' else '(–ø—Ä–æ–±—ñ–ª)'
                print(f"\n{'='*60}")
                print(f"–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –¥–ª—è —Å–∏–º–≤–æ–ª—É '{display_char}':")
                print(f"{'='*60}")
                print(f"{'–†–∞–Ω–≥':<6}{'–°–∏–º–≤–æ–ª':<15}{'–ß–∞—Å—Ç–æ—Ç–∞':<18}{'–í—ñ–¥—Å–æ—Ç–æ–∫':<12}")
                print("-" * 60)
                
                for rank, (next_char, freq) in enumerate(predictions, 1):
                    display_next = next_char if next_char != ' ' else '(–ø—Ä–æ–±—ñ–ª)'
                    print(f"{rank:<6}{display_next:<15}{freq:<18.10f}{freq*100:<12.4f}%")
                
                print(f"\n–í—Å—å–æ–≥–æ –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤: {len(predictions)}")
                
            except KeyboardInterrupt:
                print("\n\n–ü–µ—Ä–µ—Ä–≤–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–º. –î–æ –ø–æ–±–∞—á–µ–Ω–Ω—è!")
                break
            except Exception as e:
                print(f"–ü–æ–º–∏–ª–∫–∞: {e}")


def main():
    parser = argparse.ArgumentParser(
        description='–ê–Ω–∞–ª—ñ–∑ –µ–Ω—Ç—Ä–æ–ø—ñ—ó —Ç–µ–∫—Å—Ç—É –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ—ñ—á–Ω–æ–≥–æ –ø—Ä–∞–∫—Ç–∏–∫—É–º—É'
    )
    
    # –û—Å–Ω–æ–≤–Ω—ñ –∞—Ä–≥—É–º–µ–Ω—Ç–∏
    parser.add_argument('filename', nargs='?', help='–®–ª—è—Ö –¥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª—É –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É')
    parser.add_argument('--encoding', default='utf-8', 
                       help='–ö–æ–¥—É–≤–∞–Ω–Ω—è —Ñ–∞–π–ª—É (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º: utf-8)')
    parser.add_argument('--no-spaces', action='store_true',
                       help='–ê–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —Ç–µ–∫—Å—Ç –±–µ–∑ –ø—Ä–æ–±—ñ–ª—ñ–≤')
    parser.add_argument('--non-overlapping', action='store_true',
                       help='–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ –±—ñ–≥—Ä–∞–º–∏, —â–æ –Ω–µ –ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—Ç—å—Å—è')
    parser.add_argument('--both', action='store_true',
                       help='–ü–æ–∫–∞–∑–∞—Ç–∏ –∞–Ω–∞–ª—ñ–∑ —ñ –∑ –ø—Ä–æ–±—ñ–ª–∞–º–∏, —ñ –±–µ–∑ (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º)')
    
    # –ù–æ–≤—ñ –∞—Ä–≥—É–º–µ–Ω—Ç–∏ –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É —Ç–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    parser.add_argument('--export-csv', metavar='OUTPUT_FILE',
                       help='–ï–∫—Å–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ –º–∞—Ç—Ä–∏—Ü—é –±—ñ–≥—Ä–∞–º —É CSV —Ñ–∞–π–ª')
    parser.add_argument('--predict', metavar='CSV_FILE',
                       help='–ó–∞–ø—É—Å—Ç–∏—Ç–∏ —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π —Ä–µ–∂–∏–º –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è –∑ CSV —Ñ–∞–π–ª—É')
    
    args = parser.parse_args()
    
    # –†–µ–∂–∏–º –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–Ω—è
    if args.predict:
        predictor = BigramPredictor(args.predict)
        predictor.run_interactive()
        return
    
    # –ó–≤–∏—á–∞–π–Ω–∏–π —Ä–µ–∂–∏–º –∞–Ω–∞–ª—ñ–∑—É
    if not args.filename:
        parser.error("–ù–µ–æ–±—Ö—ñ–¥–Ω–æ –≤–∫–∞–∑–∞—Ç–∏ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É –∞–±–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ --predict")
    
    # –ß–∏—Ç–∞–Ω–Ω—è —Ñ–∞–π–ª—É
    try:
        with open(args.filename, 'r', encoding=args.encoding) as f:
            text = f.read()
    except FileNotFoundError:
        print(f"–ü–æ–º–∏–ª–∫–∞: –§–∞–π–ª '{args.filename}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
        sys.exit(1)
    except UnicodeDecodeError:
        print(f"–ü–æ–º–∏–ª–∫–∞: –ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª –∑ –∫–æ–¥—É–≤–∞–Ω–Ω—è–º {args.encoding}")
        print("–°–ø—Ä–æ–±—É–π—Ç–µ —ñ–Ω—à–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è, –Ω–∞–ø—Ä–∏–∫–ª–∞–¥: --encoding cp1251")
        sys.exit(1)
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞
    analyzer = TextEntropyAnalyzer(text)
    
    print("=" * 50)
    print("–ê–ù–ê–õ–Ü–ó –ï–ù–¢–†–û–ü–Ü–á –¢–ï–ö–°–¢–£")
    print("=" * 50)
    print(f"–§–∞–π–ª: {args.filename}")
    print(f"–í–∏—Ö—ñ–¥–Ω–∏–π —Ä–æ–∑–º—ñ—Ä —Ç–µ–∫—Å—Ç—É: {len(text)} —Å–∏–º–≤–æ–ª—ñ–≤")
    print(f"–û–±—Ä–æ–±–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç: {len(analyzer.processed_text)} —Å–∏–º–≤–æ–ª—ñ–≤")
    print(f"–¢–µ–∫—Å—Ç –±–µ–∑ –ø—Ä–æ–±—ñ–ª—ñ–≤: {len(analyzer.processed_text_no_spaces)} —Å–∏–º–≤–æ–ª—ñ–≤")
    
    # –í–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –∞–Ω–∞–ª—ñ–∑—É
    include_spaces = not args.no_spaces
    overlapping = not args.non_overlapping
    show_both = args.both or (not args.no_spaces and not args.both)
    
    # –ï–∫—Å–ø–æ—Ä—Ç CSV —è–∫—â–æ –∑–∞–ø–∏—Ç–∞–Ω–æ
    if args.export_csv:
        analyzer.export_bigram_matrix_csv(
            args.export_csv,
            include_spaces=include_spaces,
            overlapping=overlapping
        )
        print("\n–ï–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")
        return
    
    # –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–∏–∫–æ–Ω–∞–Ω–Ω—è —Ç–∞ –≤–∏–≤–µ–¥–µ–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É
    def run_analysis(include_spaces, overlapping):
        alphabet_size = 32 if include_spaces else 31
        mode_name = "–ó –ü–†–û–ë–Ü–õ–ê–ú–ò" if include_spaces else "–ë–ï–ó –ü–†–û–ë–Ü–õ–Ü–í"
        bigram_type = "–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ" if overlapping else "–Ω–µ–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ"
        
        print("\n" + "=" * 50)
        print(f"–ê–ù–ê–õ–Ü–ó {mode_name} ({alphabet_size} —Å–∏–º–≤–æ–ª—ñ–≤ –≤ –∞–ª—Ñ–∞–≤—ñ—Ç—ñ)")
        print(f"–ë—ñ–≥—Ä–∞–º–∏: {bigram_type}")
        print("=" * 50)
        
        # –ß–∞—Å—Ç–æ—Ç–∏ –ª—ñ—Ç–µ—Ä
        analyzer.print_letter_frequencies(include_spaces=include_spaces)
        
        # H1
        H1 = analyzer.calculate_H1(include_spaces=include_spaces)
        print(f"\nH‚ÇÅ = {H1:.4f} –±—ñ—Ç/—Å–∏–º–≤–æ–ª")
        
        # –¢–æ–ø –±—ñ–≥—Ä–∞–º–∏
        analyzer.print_top_bigrams(include_spaces=include_spaces, overlapping=overlapping)
        
        # H2
        H2 = analyzer.calculate_H2(include_spaces=include_spaces, overlapping=overlapping)
        print(f"\nH‚ÇÇ = {H2:.4f} –±—ñ—Ç/—Å–∏–º–≤–æ–ª")
        
        # –ù–∞–¥–ª–∏—à–∫–æ–≤—ñ—Å—Ç—å
        R1 = analyzer.calculate_redundancy(H1, alphabet_size)
        R2 = analyzer.calculate_redundancy(H2, alphabet_size)
        
        print(f"\n–ù–∞–¥–ª–∏—à–∫–æ–≤—ñ—Å—Ç—å R‚ÇÅ = {R1:.4f} ({R1*100:.2f}%)")
        print(f"–ù–∞–¥–ª–∏—à–∫–æ–≤—ñ—Å—Ç—å R‚ÇÇ = {R2:.4f} ({R2*100:.2f}%)")
        
        return H1, H2, R1, R2
    
    # –í–∏–∫–æ–Ω–∞–Ω–Ω—è –∞–Ω–∞–ª—ñ–∑—É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤
    results = []
    
    if show_both:
        # –ü–æ–∫–∞–∑–∞—Ç–∏ –æ–±–∏–¥–≤–∞ –∞–Ω–∞–ª—ñ–∑–∏
        print("\n" + "üîπ" * 25)
        print("–†–ï–ñ–ò–ú: –ü–æ–≤–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ (–∑ –ø—Ä–æ–±—ñ–ª–∞–º–∏ —Ç–∞ –±–µ–∑)")
        print("üîπ" * 25)
        
        # –ó –ø—Ä–æ–±—ñ–ª–∞–º–∏
        H1_with, H2_with, R1_with, R2_with = run_analysis(True, overlapping)
        results.append(("–ó –ø—Ä–æ–±—ñ–ª–∞–º–∏", H1_with, H2_with, R1_with, R2_with))
        
        # –ë–µ–∑ –ø—Ä–æ–±—ñ–ª—ñ–≤
        H1_no, H2_no, R1_no, R2_no = run_analysis(False, overlapping)
        results.append(("–ë–µ–∑ –ø—Ä–æ–±—ñ–ª—ñ–≤", H1_no, H2_no, R1_no, R2_no))
        
    else:
        # –ü–æ–∫–∞–∑–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ –æ–¥–∏–Ω –∞–Ω–∞–ª—ñ–∑
        mode = "–±–µ–∑ –ø—Ä–æ–±—ñ–ª—ñ–≤" if args.no_spaces else "–∑ –ø—Ä–æ–±—ñ–ª–∞–º–∏"
        bigram_mode = "–Ω–µ–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ –±—ñ–≥—Ä–∞–º–∏" if args.non_overlapping else "–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ –±—ñ–≥—Ä–∞–º–∏"
        print("\n" + "üîπ" * 25)
        print(f"–†–ï–ñ–ò–ú: –ê–Ω–∞–ª—ñ–∑ {mode}, {bigram_mode}")
        print("üîπ" * 25)
        
        H1, H2, R1, R2 = run_analysis(include_spaces, overlapping)
        results.append((mode.capitalize(), H1, H2, R1, R2))
    
    # –ü—ñ–¥—Å—É–º–∫–æ–≤–∞ —Ç–∞–±–ª–∏—Ü—è —è–∫—â–æ —î –∫—ñ–ª—å–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    if len(results) > 1:
        print("\n" + "=" * 50)
        print("–ü–Ü–î–°–£–ú–ö–û–í–ê –¢–ê–ë–õ–ò–¶–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í")
        print("=" * 50)
        print(f"–¢–∏–ø –±—ñ–≥—Ä–∞–º: {'–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ' if overlapping else '–Ω–µ–ø–µ—Ä–µ–∫—Ä–∏–≤–∞—é—á—ñ'}")
        print("-" * 50)
        
        print(f"{'–ú–æ–¥–µ–ª—å':<25}{'–ó –ø—Ä–æ–±—ñ–ª–∞–º–∏':<15}{'–ë–µ–∑ –ø—Ä–æ–±—ñ–ª—ñ–≤':<15}")
        print("-" * 55)
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è —Ç–∞–±–ª–∏—Ü—ñ
        with_spaces_data = results[0]
        no_spaces_data = results[1]
        
        print(f"{'H‚ÇÅ (–±—ñ—Ç/—Å–∏–º–≤–æ–ª)':<25}{with_spaces_data[1]:<15.4f}{no_spaces_data[1]:<15.4f}")
        print(f"{'H‚ÇÇ (–±—ñ—Ç/—Å–∏–º–≤–æ–ª)':<25}{with_spaces_data[2]:<15.4f}{no_spaces_data[2]:<15.4f}")
        print(f"{'–ù–∞–¥–ª–∏—à–∫–æ–≤—ñ—Å—Ç—å R‚ÇÅ (%)':<25}{with_spaces_data[3]*100:<15.2f}{no_spaces_data[3]*100:<15.2f}")
        print(f"{'–ù–∞–¥–ª–∏—à–∫–æ–≤—ñ—Å—Ç—å R‚ÇÇ (%)':<25}{with_spaces_data[4]*100:<15.2f}{no_spaces_data[4]*100:<15.2f}")
    
    # –û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ: –≤–∏–≤–µ–¥–µ–Ω–Ω—è –º–∞—Ç—Ä–∏—Ü—ñ –±—ñ–≥—Ä–∞–º
    print("\n–ë–∞–∂–∞—î—Ç–µ –≤–∏–≤–µ—Å—Ç–∏ –ø–æ–≤–Ω—É –º–∞—Ç—Ä–∏—Ü—é –±—ñ–≥—Ä–∞–º? (y/n): ", end="")
    if input().lower() == 'y':
        analyzer.print_bigram_matrix(include_spaces=include_spaces, overlapping=overlapping)


if __name__ == "__main__":
    main()
